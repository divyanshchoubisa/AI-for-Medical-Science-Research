{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA  Submission\n",
    "\n",
    "**Your Name:**\n",
    "Divyansh Choubisa\n",
    "\n",
    "**Name of your Device:**\n",
    "Chest X-Rays Pneumonia Detector\n",
    "\n",
    "## Algorithm Description \n",
    "\n",
    "### 1. General Information\n",
    "\n",
    "**Intended Use Statement:** \n",
    "Help Radiologists in detecting Pneumonia in Chest X-Rays\n",
    "\n",
    "**Indications for Use:**\n",
    "- Applicable for men and women from 1 to 90 years old\n",
    "- Chest X-Ray image must be taken in the AP or PA position\n",
    "- Chest X-Ray image must be in DICOM format\n",
    "\n",
    "**Device Limitations:**\n",
    "- Diagnosis can be made on a computer with a standard CPU, although a GPU is preferred\n",
    "\n",
    "**Clinical Impact of Performance:**\n",
    "- The model has a lower precision and higher recall\n",
    "- This means the model is most confident when the test result is negative\n",
    "- Therefore it is best used for worklist prioritization and not as a diagnosis tool\n",
    "\n",
    "### 2. Algorithm Design and Function\n",
    "<img src=\"Algo_Design_Function.JPG\"/>\n",
    "\n",
    "**DICOM Checking Steps:**\n",
    "- Modality is \"DX\"\n",
    "- Body part examined is \"CHEST\"\n",
    "- Patient Position is \"PA\" or \"AP\"\n",
    "\n",
    "**Preprocessing Steps:**\n",
    "- Image is normalized\n",
    "- Image is reshaped\n",
    "- Image is repeated across 3 channels\n",
    "\n",
    "**CNN Architecture:**\n",
    "<img src=\"Model_Arch.JPG\"/>\n",
    "\n",
    "- The model is based on the [VGG16 model](https://neurohive.io/en/popular-networks/vgg16/)\n",
    "- The model uses the first 16 layers of the VGG16 model\n",
    "- The VGG16 model output is flattened and passed through several additional dense and dropout layers\n",
    "\n",
    "\n",
    "### 3. Algorithm Training\n",
    "\n",
    "**Parameters:**\n",
    "* Types of augmentation used during training\n",
    "    - Horizontal flips\n",
    "    - No Vertical flips\n",
    "    - Height shift range of 0.1,\n",
    "    - Width shift range of 0.1,\n",
    "    - Rotation range of 25,\n",
    "    - Shear range of 0.1,\n",
    "    - Zoom range of 0.15\n",
    "* Batch size: 64\n",
    "* Optimizer learning rate: 1e-4\n",
    "* Layers of pre-existing architecture that were frozen: First 16 layers of VGG model\n",
    "* Layers of pre-existing architecture that were fine-tuned: None\n",
    "* Layers added to pre-existing architecture: Flatten, Dense and Dropout layers\n",
    "\n",
    "<img src=\"Model_Accuracy_Loss.JPG\" />\n",
    "\n",
    "<img src=\"Precision_Recall.JPG\" />\n",
    "\n",
    "**Final Threshold and Explanation:**\n",
    "\n",
    "* Threshold: 0.5215\n",
    "* F1 Score: 0.4297\n",
    "\n",
    "The final threshold of 0.5215 was based on the highest F1 Score of 0.4297. Based\n",
    "on [this paper](https://arxiv.org/pdf/1711.05225.pdf) the average radiologist has a F1 Score of 0.387. This means this\n",
    "model achieved a better performance as the average radiologist.\n",
    "\n",
    "### 4. Databases\n",
    "* The Dataset can be found here: [NIH Chest X-ray Dataset](https://www.kaggle.com/nih-chest-xrays/data)\n",
    "* It contains 112,120 chest x-ray images\n",
    "* Each image has the following meta data:\n",
    "    * Image Index\n",
    "    * Finding Labels\n",
    "    * Follow-up #\n",
    "    * Patient ID\n",
    "    * Patient Age\n",
    "    * Patient Gender\n",
    "    * View Position\n",
    "    * Original Image Size\n",
    "    * Original Image Pixel Spacing\n",
    "\n",
    "\n",
    "**Description of Training Dataset:** \n",
    "* The training data is split equally between Pneumonia and non Pneumonia patients\n",
    "* It contains 2290 images\n",
    "\n",
    "\n",
    "**Description of Validation Dataset:** \n",
    "* The training data has 20% Pneumonia and 80% non Pneumonia patients\n",
    "* It contains 1430 images\n",
    "\n",
    "### 5. Ground Truth\n",
    "\n",
    "* 112,120 X-ray images with disease labels from 30,805 unique patients\n",
    "* The disease labels were created using Natural Language Processing (NLP) to mine the associated radiological reports\n",
    "* The labels are expected to be >90% accurate and suitable for weakly-supervised learning\n",
    "* The data includes 14 common thoracic pathologies:\n",
    "    * Atelectasis\n",
    "    * Consolidation\n",
    "    * Infiltration\n",
    "    * Pneumothorax\n",
    "    * Edema\n",
    "    * Emphysema\n",
    "    * Fibrosis\n",
    "    * Effusion\n",
    "    * Pneumonia\n",
    "    * Pleural thickening\n",
    "    * Cardiomegaly\n",
    "    * Nodule\n",
    "    * Mass\n",
    "    * Hernia\n",
    "\n",
    "\n",
    "\n",
    "### 6. FDA Validation Plan\n",
    "\n",
    "**Patient Population Description for FDA Validation Dataset:**\n",
    "- Applicable for men and women from 1 to 90 years old\n",
    "- Chest X-Ray image must be taken in the AP or PA position\n",
    "- Chest X-Ray image must be in DICOM format\n",
    "\n",
    "**Ground Truth Acquisition Methodology:**\n",
    "- Silver Standard: Validation by 3 different radiologists\n",
    "\n",
    "**Algorithm Performance Standard:**\n",
    "- The algorithmâ€™s F1 score should be more than that of average radiologist (0.387)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
